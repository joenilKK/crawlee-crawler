# Mount Elizabeth Crawler - Modular Structure

## ğŸ“ Folder Organization

```
src/
â”œâ”€â”€ main.js                    # Main crawler entry point
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.js             # Configuration and settings
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ dataExtractor.js      # Data extraction logic
â”‚   â”œâ”€â”€ fileHandler.js        # File I/O operations
â”‚   â””â”€â”€ paginationHandler.js  # Pagination logic
â””â”€â”€ utils/
    â””â”€â”€ helpers.js            # Utility functions
```

## ğŸš€ Usage

Run the crawler from the project root:
```bash
node src/main.js
```

## ğŸ“ Module Descriptions

### **config/config.js**
- Site URLs and configuration
- URL filtering patterns (allowed/excluded)
- CSS selectors for scraping
- Crawler settings (headless, timeout, etc.)
- Output file naming

### **handlers/dataExtractor.js**
- Extract doctor names and contact details
- Handle extraction errors gracefully
- Format extracted data consistently

### **handlers/fileHandler.js**
- Save data to JSON files with metadata
- Create backups of existing files
- Handle file system operations

### **handlers/paginationHandler.js**
- Check for next page availability
- Generate next page URLs
- Handle both initial and subsequent pagination

### **utils/helpers.js**
- Date formatting utilities
- URL validation
- Filename sanitization
- General helper functions

## ğŸ”§ Configuration

To crawl a different site, update `config/config.js`:

```javascript
SITE: {
    name: 'New Hospital',
    baseUrl: 'https://newhospital.com/',
    startUrl: 'https://newhospital.com/doctors/',
    allowedUrlPatterns: [
        'https://newhospital.com/doctors/',
        'https://newhospital.com/doctors/*'
    ],
    excludedUrlPatterns: [
        'https://newhospital.com/admin/*',
        'https://newhospital.com/services/*'
    ]
},
SELECTORS: {
    specialistLinks: '.doctor-list a',
    doctorName: '.doctor-name h1'
    // ... other selectors
}
```

### **URL Filtering**
- **allowedUrlPatterns**: Only URLs matching these patterns will be crawled
- **excludedUrlPatterns**: URLs matching these patterns will be skipped
- Supports wildcards (`*`) for flexible pattern matching
- Excluded patterns take precedence over allowed patterns

## ğŸ“Š Output

Data is saved as: `mountelizabeth-specialists-YYYY-MM-DD.json`

Contains:
- Site metadata
- Extraction timestamp
- Total record count
- Array of specialist data
